import streamlit as st
import torch
import tempfile
import os
import shutil
import cv2
from PIL import Image
import numpy as np

st.set_page_config(page_title="Ignition Point Detector", layout="centered")

# ìƒë‹¨ ì œëª© ë° ë¡œê³ 
st.image("logoall.jpg", use_column_width=True)
st.markdown("<h1 style='text-align: center;'>ğŸ”¥ ë°œí™”ì  ê²€ì¶œê¸°</h1>", unsafe_allow_html=True)

# ì—…ë¡œë“œ ì„¹ì…˜
st.markdown("### YOLOv5 ëª¨ë¸ ê°€ì¤‘ì¹˜ (.pt)")
model_file = st.file_uploader("ì—¬ê¸°ì— íŒŒì¼ì„ ëŒì–´ë‹¤ ë†“ìŠµë‹ˆë‹¤.", type=["pt"], key="model")

st.markdown("### ë¶„ì„í•  í™”ì¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
image_files = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"], accept_multiple_files=True, key="images")

# ì˜ˆì¸¡ ìˆ˜í–‰ í•¨ìˆ˜
def load_model(pt_path):
    model = torch.hub.load('ultralytics/yolov5', 'custom', path=pt_path, force_reload=True)
    return model

def run_inference(model, image):
    results = model(image)
    return results

def draw_results(results, img_np):
    for *box, conf, cls in results.xyxy[0].tolist():
        x1, y1, x2, y2 = map(int, box)
        label = f'{results.names[int(cls)]} {conf:.2f}'
        cv2.rectangle(img_np, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img_np, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
    return img_np

# ì˜ˆì¸¡ ì‹¤í–‰
if model_file and image_files:
    with tempfile.TemporaryDirectory() as tmpdir:
        # ëª¨ë¸ ì €ì¥
        model_path = os.path.join(tmpdir, "model.pt")
        with open(model_path, "wb") as f:
            f.write(model_file.read())

        st.success("âœ… ëª¨ë¸ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
        try:
            model = load_model(model_path)
            st.success("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

            for uploaded_image in image_files:
                st.markdown("---")
                st.subheader(f"ğŸ“· ì…ë ¥ ì´ë¯¸ì§€: {uploaded_image.name}")
                image = Image.open(uploaded_image).convert("RGB")
                st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)

                # PIL â†’ OpenCV ë³€í™˜
                img_np = np.array(image)
                img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

                # ì˜ˆì¸¡
                results = run_inference(model, img_bgr)

                # ê²°ê³¼ ì‹œê°í™”
                img_result = draw_results(results, img_bgr.copy())
                img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)

                st.image(img_result_rgb, caption="ğŸ” ì˜ˆì¸¡ ê²°ê³¼", use_column_width=True)
        except Exception as e:
            st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    st.warning("YOLOv5 ê°€ì¤‘ì¹˜ íŒŒì¼ê³¼ ë¶„ì„í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
