import os
import tempfile

import cv2
import streamlit as st
import torch

from models.common import DetectMultiBackend
from utils.datasets import LoadImages
from utils.general import check_img_size, non_max_suppression, scale_coords
from utils.torch_utils import select_device

# ê¸°ë³¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ
DEFAULT_WEIGHT_PATH = "runs/train/ignition_yolo_final_retrain2/weights/best.pt"

# ì´ë¯¸ì§€ í‘œì‹œ í¬ê¸°
IMG_DISPLAY_WIDTH = 800

# Streamlit ìƒë‹¨ ë””ìì¸
st.set_page_config(layout="centered")
st.markdown("<h1 style='text-align: center;'>ğŸ”¥ Ignition Point Detector</h1>", unsafe_allow_html=True)

# ë¡œê³  ì´ë¯¸ì§€ í‘œì‹œ
if os.path.exists("logoall.jpg"):
    st.image("logoall.jpg", width=500)
else:
    st.warning("ë¡œê³  ì´ë¯¸ì§€ (logoall.jpg)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ
weights = DEFAULT_WEIGHT_PATH
if not os.path.exists(weights):
    weights = st.file_uploader("YOLOv5 ëª¨ë¸ ê°€ì¤‘ì¹˜ (.pt)", type=["pt"])
    if weights:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pt") as tmp:
            tmp.write(weights.read())
            weights = tmp.name
    else:
        st.error("ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()

# YOLOv5 ëª¨ë¸ ì´ˆê¸°í™”
device = select_device("")
model = DetectMultiBackend(weights, device=device)
stride, names = model.stride, model.names
imgsz = check_img_size(640, s=stride)

# ğŸ” ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_files = st.file_uploader(
    "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš” (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", type=["jpg", "jpeg", "png"], accept_multiple_files=True
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        st.subheader(f"ğŸ“· {uploaded_file.name}")
        # ì„ì‹œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_img:
            tmp_img.write(uploaded_file.read())
            img_path = tmp_img.name

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        dataset = LoadImages(img_path, img_size=imgsz, stride=stride)
        for path, im, im0s, _ in dataset:
            im = torch.from_numpy(im).to(device)
            im = im.float() / 255.0
            if im.ndimension() == 3:
                im = im.unsqueeze(0)

            pred = model(im)
            pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)

            for i, det in enumerate(pred):
                im0 = im0s.copy()
                if len(det):
                    det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()
                    for *xyxy, conf, cls in reversed(det):
                        label = f"{names[int(cls)]} {conf:.2f}"
                        cv2.rectangle(im0, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 0, 255), 2)
                        cv2.putText(
                            im0, label, (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2
                        )

                # ê²°ê³¼ í‘œì‹œ
                im0_rgb = cv2.cvtColor(im0, cv2.COLOR_BGR2RGB)
                st.image(im0_rgb, caption="ì˜ˆì¸¡ ê²°ê³¼", width=IMG_DISPLAY_WIDTH)
