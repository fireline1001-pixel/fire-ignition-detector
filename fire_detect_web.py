import streamlit as st
import torch
import tempfile
import os
import shutil
from PIL import Image
import cv2
import numpy as np
from datetime import datetime

# ìƒë‹¨ ë¡œê³  ë° ì œëª© í‘œì‹œ
st.set_page_config(page_title="Ignition Point Detector", layout="centered")
st.markdown(
    """
    <div style='text-align: center; padding: 10px 0;'>
        <img src="https://raw.githubusercontent.com/fireline1001-pixel/fire-ignition-detector/main/logoall.jpg" width="300"/>
        <h2>Ignition Point Detector ğŸ”¥</h2>
    </div>
    """,
    unsafe_allow_html=True
)

# ëª¨ë¸ ì—…ë¡œë“œ
st.sidebar.header("1ï¸âƒ£ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ")
uploaded_model = st.sidebar.file_uploader("YOLOv5 .pt íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pt"])

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
st.sidebar.header("2ï¸âƒ£ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
uploaded_images = st.sidebar.file_uploader("ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

# ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_model_from_uploaded_file(uploaded_file):
    temp_dir = tempfile.mkdtemp()
    model_path = os.path.join(temp_dir, "model.pt")
    with open(model_path, "wb") as f:
        f.write(uploaded_file.read())
    model = torch.load(model_path, map_location=torch.device('cpu'))
    model.eval()
    return model

# ì˜ˆì¸¡ ìˆ˜í–‰
def run_inference(model, image_pil):
    img = np.array(image_pil)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = model([img_rgb], size=640)
    return results

# ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
def draw_boxes(image_pil, results):
    img = np.array(image_pil).copy()
    for *xyxy, conf, cls in results.xyxy[0].tolist():
        label = f"{results.names[int(cls)]} {conf:.2f}"
        x1, y1, x2, y2 = map(int, xyxy)
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
    return Image.fromarray(img)

# ë©”ì¸ ì‹¤í–‰
if uploaded_model and uploaded_images:
    model = load_model_from_uploaded_file(uploaded_model)

    st.header("3ï¸âƒ£ ì˜ˆì¸¡ ê²°ê³¼")

    for uploaded_image in uploaded_images:
        st.subheader(f"ğŸ” ë¶„ì„ ì¤‘: {uploaded_image.name}")
        image_pil = Image.open(uploaded_image).convert("RGB")
        results = run_inference(model, image_pil)
        image_with_boxes = draw_boxes(image_pil, results)

        st.image(image_with_boxes, caption=f"ğŸ“ ì˜ˆì¸¡ ê²°ê³¼ - {uploaded_image.name}", use_column_width=True)

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        temp_img_path = f"result_{timestamp}.jpg"
        image_with_boxes.save(temp_img_path)
        with open(temp_img_path, "rb") as f:
            btn = st.download_button(
                label="ğŸ“¥ ê²°ê³¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                data=f,
                file_name=f"predicted_{uploaded_image.name}",
                mime="image/jpeg"
            )
        os.remove(temp_img_path)

elif not uploaded_model:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ YOLOv5 ê°€ì¤‘ì¹˜(.pt) íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
elif not uploaded_images:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
